{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input/landmark-recognition-challenge\"))",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'sample_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
      },
      "cell_type": "markdown",
      "source": "# Exploratory Analysis :\n-------------------------------------------------"
    },
    {
      "metadata": {
        "_cell_guid": "c28b660a-f713-41fb-b42c-baf78d8e9978",
        "_uuid": "ebf1af925d7892dbb7a5830da88bb575c123dec7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#train_data = pd.read_csv('../input/landmark-recognition-challenge/train.csv')\ntrain_data = pd.read_csv('../input/landmark-dataset-url-analysis/trainsmall.csv')\ntest_data = pd.read_csv('../input/landmark-recognition-challenge/test.csv')\nsubmission = pd.read_csv(\"../input/landmark-recognition-challenge/sample_submission.csv\")\ntrain_data['id'] = train_data['id'].astype('category')\ntrain_data['url'] = train_data['url'].astype('category')\ntrain_data.head(4)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "                 id     ...     landmark_id\n0  cacf8152e2d2ae60     ...            4676\n1  0a58358a2afd3e4e     ...            6651\n2  6b2bb500b6a38aa0     ...           11284\n3  b399f09dee9c3c67     ...            8429\n\n[4 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>landmark_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cacf8152e2d2ae60</td>\n      <td>http://static.panoramio.com/photos/large/70761...</td>\n      <td>4676</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0a58358a2afd3e4e</td>\n      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n      <td>6651</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6b2bb500b6a38aa0</td>\n      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n      <td>11284</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b399f09dee9c3c67</td>\n      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n      <td>8429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "9840fd78-dd5f-41f8-baba-0c1d46a330f2",
        "_uuid": "18250a1e698290545e98b20e6bc9b9ada52e8288",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_data.info(); print(\"-\" * 20);\ntest_data.info(); print(\"-\" * 20);",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1225020 entries, 0 to 1225019\nData columns (total 3 columns):\nid             1225020 non-null category\nurl            1225020 non-null category\nlandmark_id    1225020 non-null int64\ndtypes: category(2), int64(1)\nmemory usage: 117.4 MB\n--------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 117703 entries, 0 to 117702\nData columns (total 2 columns):\nid     117703 non-null object\nurl    117703 non-null object\ndtypes: object(2)\nmemory usage: 1.8+ MB\n--------------------\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "8bef751f-7018-4f4a-80da-66c719e03502",
        "_uuid": "dfde3393653fe985c23fe6d8b0ce5343e7bc7410",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# -> We can see that there are no missing values in both test and train data\nprint(\"Unique values in Train :\\n\",train_data.nunique())\nprint(\"Unique values in Test :\\n\",test_data.nunique())\n\n# -> In the train dataset, there are only 14951 unique landmark_id data. All id's and url's are unique.\n# -> All id's and url's are unique in the test data as well.\n\n# Concatenate Train and test data\nconcatenated = pd.concat([train_data, test_data])\nprint(\"The shape of the resulted DataFrame: \",concatenated.shape)\nconcatenated.nunique()\n\n# -> All id's and url's are unique for the concatenated data. That means we do not have any id's or url's from train dataset leaked in the test data set as well.\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d29898f5-f1bb-4d76-b9c3-197d6d7e73a6",
        "scrolled": false,
        "_uuid": "0d5f11fc4c0e1addc94d25b9ab8964248ff45517",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Occurance of landmark_id in decreasing order(Top categories)\nIMAGES_NUMBER = 50\n#temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(40))\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(IMAGES_NUMBER))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id','count']\n\n# Plot the most frequent landmark_ids\nplt.figure(figsize = (25, 8))\nplt.title('Most frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp)\nplt.show()\n\n# -> The most frequent landmark_id is 9633 and the count is 50337.\n# -> There are many least frequent landmarks whose count is 1\n\nplt.figure(figsize=(25, 8))\nplt.title(\"Category distribution\")\nsns.distplot(train_data[\"landmark_id\"], bins=150)\nplt.show()\n\nprint(\"Number of classes under 25 occurence \",(train_data[\"landmark_id\"].value_counts() <= 25).sum() ,\" of \", len(train_data[\"landmark_id\"].unique()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "28520e63-4e23-4fc2-8789-48a87b8c9a31",
        "_uuid": "bf7d60b3abdd4324aa255dfbbf76973174b8af2d"
      },
      "cell_type": "markdown",
      "source": "# Display some images from URLs / Some URLs Visulization"
    },
    {
      "metadata": {
        "_cell_guid": "d1d11755-3213-4e32-9ca5-748c681cc932",
        "scrolled": false,
        "_uuid": "1a0eae82c549d00b3b6fe5097e59ad3c68bad9a7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \n\ndef displayLandmarkImagesLarge(urls, category_name):\n    img_style = \"width: 200px; height:160px; margin: 0px; float: left; border: 1px solid black;\"\n    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n    display(HTML(images_list))\n\ncategory = train_data['landmark_id'].value_counts().keys()[15]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplayLandmarkImagesLarge(urls, \"\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "50278ddc-05a6-41e6-a8fa-3e6dda62b0da",
        "_uuid": "531a0c757477d5f8c4177c15d426802ff684bb3f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Visualize 6 images for each of the first 5 landmarks, ordered by the number of occurences.\nLANDMARK_NUMBER = 5\nIMAGES_NUMBER = 6\nlandMarkIDs = pd.Series(train_data['landmark_id'].value_counts().keys())[1:LANDMARK_NUMBER+1]\nfor landMarkID in landMarkIDs:\n    url = train_data[train_data['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n    displayLandmarkImagesLarge(url, \"\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "16c854db-a8d4-4951-8846-9bbec4056a52",
        "_uuid": "81935c2a5e95faec2691acd82a0b889cfc7eb74f"
      },
      "cell_type": "markdown",
      "source": "# Extracting website name and adding new Column \"site_name\""
    },
    {
      "metadata": {
        "_cell_guid": "1114d2bc-3fb5-47cd-bfad-1069a0eb826b",
        "scrolled": false,
        "_uuid": "b0c9e66a452f73ee5ba9a0597ee50a5a4d45c687",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Extract site_names from train data\ntemp_list = list()\nfor path in train_data['url']:\n    temp_list.append((path.split('//',1)[1]).split('/', 1)[0])\ntrain_data['site_name'] = temp_list\n# Extract site_names from test data\ntemp_list = list()\nfor path in test_data['url']:\n    temp_list.append((path.split('//', 1)[1]).split('/',1)[0])\ntest_data['site_name'] = temp_list\n\n# Occurence of site in decreasing order(Top categories)\ntemp_train = pd.DataFrame(train_data.site_name.value_counts())\ntemp_test = pd.DataFrame(test_data.site_name.value_counts())\n\ntemp_train.reset_index(inplace= True); temp_test.reset_index(inplace= True)\ntemp_train.columns = temp_test.columns = ['site_name', 'count']\n# Plot The sites with teir count\ndef draw_plot_site_names(SData):\n    plt.figure(figsize=(25, 8))\n    plt.title('Sites with their count')\n    sns.set_color_codes(\"pastel\")\n    sns.barplot(x=\"site_name\", y=\"count\", data=SData, label=\"Count\")\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=90)\n    plt.show()\ndraw_plot_site_names(temp_train)\ndraw_plot_site_names(temp_test)\n# Total unique sites are 16 in train and 25 in test data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e877ba1b-19ce-4da8-82e2-93812ac52357",
        "_uuid": "140c8974ec3768ddab61aef9adad39814153dc13",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# the expected format for the submission file\nsubmission.head(6)\n\n# -> Submission has two columns : an landmark id that is associated with the image and its corresponding confidence score.\n# -- Some query images may contain no landmarks. For these, one can submit no landmark id (and no confidence score).",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d50761c4-a1fb-425a-bed8-bd36a0ba4dbb",
        "_uuid": "0d68b53c09f2ed908c0b3917aca9d5bde0417fec"
      },
      "cell_type": "markdown",
      "source": "# Random Guessing"
    },
    {
      "metadata": {
        "_cell_guid": "4b3c2937-21f4-4429-869c-d77a655bed80",
        "_uuid": "c8d9ad6085cd9b5d5f98fcf8cb570435bb76f4dd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# take the most frequent label\ndef_guess = train_data['landmark_id'].value_counts()/train_data['landmark_id'].value_counts().sum()\n\nnp.random.seed=15\nr_idx = lambda : np.random.choice(def_guess.index, p = def_guess.values)\n\nr_score = lambda idx: '%d %2.4f' % (def_guess.index[idx], def_guess.values[idx])\nsubmission['landmarks'] = submission.id.map(lambda _: r_score(r_idx()))\nsubmission.to_csv('rand_submission.csv', index=False)\nsubmission.sample(2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "bb4f4a5e-c979-4fd0-a0c5-f7c6f1e91a45",
        "_uuid": "db0a44a1313e1d6361c86d15ae7c078f0ef6a56e"
      },
      "cell_type": "markdown",
      "source": "Reference: \n* [https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis](https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis)\n* [https://www.kaggle.com/gpreda/google-landmark-recogn-challenge-data-exploration](https://www.kaggle.com/gpreda/google-landmark-recogn-challenge-data-exploration)\n* [https://www.kaggle.com/kmader/baseline-landmark-model](https://www.kaggle.com/kmader/baseline-landmark-model)"
    },
    {
      "metadata": {
        "_cell_guid": "f9126a64-d9df-40c3-810b-f5f77018e23d",
        "_uuid": "a772819ae088668d48cb0979bfc0978334f8b9cb",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#import random\n#random.seed = 22\n#np.random.seed = 22\n#for i in range(5):\n#    vals = train_data.landmark_id.value_counts().index\n#    submission['landmarks'] = submission['landmarks'].map(lambda x: ' '.join(map(str, [random.choice(vals), round(random.random(), 2)])))\n#    submission.to_csv('submission' + str(i+1).zfill(2) +'.csv', index=False)\n#    submission.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "77768930-3bb6-4b98-9ad4-40c40dab08f5",
        "_uuid": "3fa9087f3e3e44d410f6d4cf250c03739af8057e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Use only the first 1000 most frequent landmarks in train set for building the test set values\nimport pylab as pl\npl.seed = 0\nN = 1500\nprobs = train_data.landmark_id.value_counts() / train_data.shape[0]\nprobs = probs.iloc[:N]\nprobs = pd.DataFrame({'landmark_id': probs.index,\n                      'probability': probs.values}, index=pl.arange(N))\nT = pd.merge(train_data, probs, on='landmark_id', how='inner')\ninx = pl.randint(0, T.shape[0], submission.shape[0])\nsubmission['landmark_id'] = T.landmark_id.iloc[inx].values\nsubmission['prob'] = T.probability.iloc[inx].values\nsubmission['landmarks'] = submission.landmark_id.astype(str) + ' ' + submission.prob.astype(str)\nsubmission[['id','landmarks']].to_csv('submission_MFreq.csv', index=False)\nsubmission[['id','landmarks']].head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c8a3c645-76ee-4b54-b611-43c063a7e8fd",
        "_uuid": "c52685ff914b243cb3ecd2c821a02d0510fe6352",
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}