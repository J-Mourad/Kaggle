{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# necessary packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime\nfrom pprint import pprint\nfrom os.path import join as pjoin\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\n\nimport math\nimport os\nfrom scipy.stats import kurtosis, skew\nfrom IPython import embed\nfrom IPython.terminal.embed import InteractiveShellEmbed\n\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport shap\n\nplt.rcParams['figure.figsize'] = (15,7)\ndata_root = '../input/build-my-data'\nprint(os.listdir(data_root))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4889c339e4f940414d39d3eec3d9b6cbd07b3649"},"cell_type":"markdown","source":"## 1 - data reading "},{"metadata":{"trusted":true,"_uuid":"b33bf2cc1a1bd5d07f23ce502194691e331b69d2"},"cell_type":"code","source":"def load_data(data='train',n=2):\n    df = pd.DataFrame()\n    for i in range(n) :\n        if data=='train':\n            if i > 8 :\n                break\n            dfpart = pd.read_pickle(pjoin(data_root,f'train_{i}.pkl'))\n        elif data=='test':\n            if i > 2 :\n                break\n            dfpart = pd.read_pickle(pjoin(data_root,f'test_{i}.pkl'))\n        df = pd.concat([df,dfpart])\n        del dfpart\n    return df\n\n%time\ndf_train = load_data(n=9)\ndf_test = load_data('test',n=4)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c184a38898811e668f3414bd28706ce314abfae2"},"cell_type":"code","source":"#df_train.isnull().sum()\n#df_test.isnull().sum()\ndf_all = pd.concat([df_train,df_test]).reset_index(drop=True)\nprint({\"all\":df_all.shape,\n       \"df_train\":df_train.shape,\n       \"df_test\":df_test.shape,})\ndf_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d8b74e9102aefd40b21c214b39cee756694d052"},"cell_type":"code","source":"def feature_engineering(df):\n    df = df.copy()\n    \n    df['month_unique_user_count'] = df.groupby('Date_Month')['fullVisitorId'].transform('nunique')\n    df['day_unique_user_count'] = df.groupby('Date_Day')['fullVisitorId'].transform('nunique')\n    df['sum_pageviews_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_pageviews'].transform('sum')\n    df['mean_pageviews_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_pageviews'].transform('mean')\n    df['sum_hits_per_day'] = df.groupby(['Date_Day'])['totals_hits'].transform('sum')\n    df['count_pageviews_per_region'] = df.groupby('geoNetwork_region')['totals_pageviews'].transform('count')\n    df['mean_pageviews_per_region'] = df.groupby('geoNetwork_region')['totals_pageviews'].transform('mean')\n    df['sum_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('sum')\n    df['sum_hits_per_region'] = df.groupby('geoNetwork_region')['totals_hits'].transform('sum')\n    df['sum_hits_per_country'] = df.groupby('geoNetwork_country')['totals_hits'].transform('sum')\n    df['user_pageviews_sum'] = df.groupby('fullVisitorId')['totals_pageviews'].transform('sum')\n    df['user_hits_sum'] = df.groupby('fullVisitorId')['totals_hits'].transform('sum')\n    \n    print(\"Done........\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49dfe712d2f1092efccab25170377b2291da39a6"},"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n\n# label encoder for categorical attributes\ndef encode_data(df ,verbose=False):\n    df = df.copy()\n    for col in df.columns:\n        if df[col].dtype == 'object' and col not in ['fullVisitorId','visitId','visitStartTime','date']:\n            if verbose:\n                print(col)\n            lb = LabelEncoder()\n            lb.fit( list(df[col].unique()))\n            df[col] = lb.transform(df[col])\n    return df \n\ndf_all=encode_data(df_all,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"253595432b06ea4d19a3232eee9a287528bfe1ce"},"cell_type":"code","source":"def generate_label(label,id_dfx):\n    col_label=['fullVisitorId','totals_transactionRevenue']\n    \n    #Select only the id is in df_train for the label\n    label = label[label.fullVisitorId.isin(id_dfx)].copy()\n    label=label.reset_index(drop=True)\n    \n    #drop all columuns else fullvisitorsid and totaltransations\n    for c in label.columns:\n        if(c not in col_label ):\n            label.drop(c,axis=1,inplace=True)\n            \n    #Select the id in train not in label       \n    id_label = label.fullVisitorId.drop_duplicates()\n    not_in_label=list(set(id_dfx) - set(id_label))\n    zeros=[0 for c in range(0,len(not_in_label))]\n    df_label_0=pd.DataFrame(list(zip(not_in_label, zeros)) ,columns=['fullVisitorId','totals_transactionRevenue'])\n    \n    #Contatane  dataframes label and df_label_0\n    label=pd.concat([label,df_label_0]).reset_index(drop=True)\n    return label","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6073ad46edd887fe588bc4cdc4c56e6c8cfefc61"},"cell_type":"markdown","source":"## 2- Data Splitting times series"},{"metadata":{"trusted":true,"_uuid":"75c719f8dc471c3e8c9b46d830d89f124c75d7b1","scrolled":true},"cell_type":"code","source":"# train_v2.csv - from August 1st 2016 to April 30th 2018.\n# test_v2.csv - from May 1st 2018 to October 15th 2018.\n# sample_submission_v2.csv - from December 1st 2018 to January 31st 2019\n#test\n#df_test_x = df_all[(df_all.date >= \"2018-05-01\") & (df_all.date <= \"2018-10-15\")].copy()\n#df_test_x =df_test_x.reset_index(drop=True)\n\n#train1 \ndf_train1_x = df_all[df_all.date <= \"2016-12-30\"].copy() #5 months(august ---> dec)\ndf_train1_x=df_train1_x.reset_index(drop=True)\nlabel_1 = df_all[(df_all.date >= \"2017-01-01\") & (df_all.date <= \"2017-03-01\")].copy() #2 months (jan--->feb)\nid_train1 = df_train1_x.fullVisitorId.drop_duplicates()\n\n#Generate label\nlabel_1=generate_label(label_1,id_train1).copy()\n\n# feature engeneering\ndf_train1_x=feature_engineering(df_train1_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee94cdabea21c2b3e859f98b3a9ee9bccf2a3a91"},"cell_type":"code","source":"from datetime import datetime\nfrom dateutil.relativedelta import relativedelta\ndef three_month_after(train_begin,train_end,label_begin,label_end,verbose=False):\n    # three moth ago for each date\n    tb=datetime.strptime(train_begin,'%Y-%m-%d')+relativedelta(months=3);\n    te=datetime.strptime(train_end,'%Y-%m-%d')+relativedelta(months=3);\n    lb=datetime.strptime(label_begin,'%Y-%m-%d')+relativedelta(months=3);\n    le=datetime.strptime(label_end,'%Y-%m-%d')+relativedelta(months=3);\n    if verbose:\n        print(\"train---------------------------------\")\n        print( 'intial:',datetime.strptime(train_begin,'%Y-%m-%d'))\n        print( 'After 3 Month:', tb.strftime('%Y-%m-%d'))\n        print( 'intial:',datetime.strptime(train_end,'%Y-%m-%d'))\n        print( 'After 3 Month:', te.strftime('%Y-%m-%d'))\n        print(\"label---------------------------------\")\n        print( 'intial:',datetime.strptime(label_begin,'%Y-%m-%d'))\n        print( 'After 3 Month:', lb.strftime('%Y-%m-%d'))\n        print( 'intial:',datetime.strptime(label_end,'%Y-%m-%d'))\n        print( 'After 3 Month:', le.strftime('%Y-%m-%d'))\n    \n    # Generate df _ train for 5 month\n    df_x = df_all[ (df_all.date >= tb.strftime('%Y-%m-%d')) & (df_all.date <= te.strftime('%Y-%m-%d'))].copy() #5,5 months(oct ---> march *0.5)\n    df_x=df_x.reset_index(drop=True)\n    #<-> 1.5 month \n    label = df_all[(df_all.date >= lb.strftime('%Y-%m-%d')) & (df_all.date <= le.strftime('%Y-%m-%d'))].copy() #2 months (may--->june)\n    id_train = df_x.fullVisitorId.drop_duplicates()\n\n    #Generate label 2 month\n    label=generate_label(label,id_train).copy()\n    \n    return df_x,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83fb0949b48e4a2f9564ebffeb5f6df52a6a7f5a"},"cell_type":"code","source":"#train2\ndf_train2_x,label_2=three_month_after(\"2016-08-01\",\"2016-12-30\",\"2017-01-01\",\"2017-03-01\",verbose=True)\n# feature engeneering\ndf_train2_x=feature_engineering(df_train2_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4e2a32f5395c62c9a9764967d7f67d8105b900f"},"cell_type":"code","source":"#train3 \ndf_train3_x,label_3=three_month_after(\"2016-11-01\",\"2017-03-30\",\"2017-04-01\",\"2017-06-01\",verbose=True)\n# feature engeneering\ndf_train3_x=feature_engineering(df_train3_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5479a23e9bf88645b50426fce60fb8f5d7412e8"},"cell_type":"code","source":"#train4 \ndf_train4_x,label_4=three_month_after(\"2017-02-01\",\"2017-06-30\",\"2017-07-01\",\"2017-09-01\",verbose=True)\n# feature engeneering\ndf_train4_x=feature_engineering(df_train4_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c87c1b5ce8a387a4caff9cfd3ccec7fb274da47"},"cell_type":"code","source":"#train5 \ndf_train5_x,label_5=three_month_after(\"2017-05-01\",\"2017-09-30\",\"2017-10-01\",\"2017-12-01\",verbose=True)\n# feature engeneering\ndf_train5_x=feature_engineering(df_train5_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34f7d1f84c1637747a879878eaf95c03aaab1777"},"cell_type":"code","source":"#train6\ndf_train6_x,label_6=three_month_after(\"2017-08-01\",\"2017-12-30\",\"2018-01-01\",\"2018-03-01\",verbose=True)\n# feature engeneering\ndf_train6_x=feature_engineering(df_train6_x).copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d86405fe9e98abb64a7c9e9fb9a927657cb9bb4"},"cell_type":"markdown","source":"## 3- Data Aggregating"},{"metadata":{"trusted":true,"_uuid":"9e7dc922b3bab3b11c2d910b91c6f242cf929d5f"},"cell_type":"code","source":"def group_by_fullVistorsId(df_x,y):\n    cat_cols=[\"channelGrouping\",\"device_browser\",\"device_deviceCategory\",\"device_operatingSystem\",\"geoNetwork_city\",\n          \"geoNetwork_continent\",\"geoNetwork_country\",\"geoNetwork_metro\", \"geoNetwork_networkDomain\",\n          \"geoNetwork_region\",\"geoNetwork_subContinent\", \"trafficSource_adContent\",\n          \"trafficSource_adwordsClickInfo.adNetworkType\",\"trafficSource_adwordsClickInfo.gclId\",\n          \"trafficSource_adwordsClickInfo.slot\",\"trafficSource_campaign\",\"trafficSource_keyword\",\n          \"trafficSource_medium\",\"trafficSource_referralPath\",\"trafficSource_source\",\"customDimensions_value\"]\n    \n    eng_cols= ['sum_hits_per_country', 'month_unique_user_count', 'sum_pageviews_per_network_domain', 'mean_pageviews_per_region',\n    'sum_hits_per_network_domain','count_pageviews_per_region', 'sum_hits_per_day','mean_pageviews_per_network_domain',\n    'user_pageviews_sum', 'user_hits_sum', 'day_unique_user_count', 'sum_hits_per_region']\n\n    # for categorrials columns\n    last_cols = cat_cols + [\"fullVisitorId\"]\n    df_x_agg_last = df_x[last_cols].groupby(\"fullVisitorId\",as_index=False).last().sort_values(\"fullVisitorId\").reset_index(drop=True).copy()\n    \n    # for numeric columns\n    num_cols = [item for item in df_train.columns if \"totals\" in item]\n    sum_cols = num_cols + eng_cols + [\"fullVisitorId\"]\n    df_x_agg_sum = df_x[sum_cols].groupby(\"fullVisitorId\",as_index=False).sum().sort_values(\"fullVisitorId\").reset_index(drop=True).copy()\n    y_agg = y[[\"fullVisitorId\",'totals_transactionRevenue']].groupby(\"fullVisitorId\",as_index=False).sum().sort_values(\"fullVisitorId\").reset_index(drop=True).copy()\n    \n    # log for totals_transactionRevenue\n    df_x_agg_sum['totals_transactionRevenue'] = np.log1p(df_x_agg_sum['totals_transactionRevenue'])\n    y_agg['totals_transactionRevenue'] = np.log1p(y_agg['totals_transactionRevenue'])\n    \n    # merge horizontaly dataframes\n    df_x_agg = pd.merge(df_x_agg_sum,df_x_agg_last, how='left',on=\"fullVisitorId\").sort_values(\"fullVisitorId\").reset_index(drop=True).copy()\n    print(\"Done.........\")\n    return df_x_agg,y_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b7457fb381454f08cb6b606e880c8d135f6160d"},"cell_type":"code","source":"# group by dataframes\ndf_train1_agg,label1_agg=group_by_fullVistorsId(df_train1_x,label_1)\ndf_train2_agg,label2_agg=group_by_fullVistorsId(df_train2_x,label_2)\ndf_train3_agg,label3_agg=group_by_fullVistorsId(df_train3_x,label_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3586f74178e4b320cdbdd464f54bbfcaae95fb3"},"cell_type":"code","source":"df_train4_agg,label4_agg=group_by_fullVistorsId(df_train4_x,label_4)\ndf_train5_agg,label5_agg=group_by_fullVistorsId(df_train5_x,label_5)\ndf_train6_agg,label6_agg=group_by_fullVistorsId(df_train6_x,label_6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd1a1f9fd9ad463d053a43db23ae7eb6d033c034"},"cell_type":"code","source":"# drop no trainning attributes\n\n#fold1\n#train \ndf_train1_agg = df_train1_agg.drop([\"fullVisitorId\"],axis=1)\nlabel1_agg= label1_agg[\"totals_transactionRevenue\"]\n#validation\ndf_train2_agg = df_train2_agg.drop([\"fullVisitorId\"],axis=1)\nlabel2_agg= label2_agg[\"totals_transactionRevenue\"]\n\n#fold2\n#train : df_train2_agg,label2_agg\n#validation\ndf_train3_agg = df_train3_agg.drop([\"fullVisitorId\"],axis=1)\nlabel3_agg= label3_agg[\"totals_transactionRevenue\"]\n\n#fold3\n#train :df_train3_agg,label3_agg\n#validation\ndf_train4_agg = df_train4_agg.drop([\"fullVisitorId\"],axis=1)\nlabel4_agg= label4_agg[\"totals_transactionRevenue\"]\n\n#fold4\n#train :df_train4_agg,label4_agg\n#validation\ndf_train5_agg = df_train5_agg.drop([\"fullVisitorId\"],axis=1)\nlabel5_agg= label5_agg[\"totals_transactionRevenue\"]\n\n#fold5\n#train :df_train5_agg,label5_agg\n#validation\ndf_train6_agg = df_train6_agg.drop([\"fullVisitorId\"],axis=1)\nlabel6_agg= label6_agg[\"totals_transactionRevenue\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a52681dfb97136f1a5aca12794543e6fb31a8316"},"cell_type":"markdown","source":"## 4- Grid Search"},{"metadata":{"trusted":true,"_uuid":"a944a9dcd67cb3481905a6c0feff34957c810d07"},"cell_type":"code","source":"#params to do un grid search\n#max_depth= [3,10,15,30]\nimport lightgbm as lgb\nn_estimators = [100,500,1000,2000]\nlearning_rate=[0.001,0.01,0.1]\nmin_child_samples=[40,50,60] \nnum_leaves=[28,31,35,38] \nlearning_rate=[0.005,0.01,0.1,0.5]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2c5c994ba2bbcb7fc7a246dbe66f058342d4d05"},"cell_type":"code","source":"import lightgbm as lgb\nprint('Starting Grid Search ...')\nmean=[]\navg=[]\naxis_x=[]\n\nfor i in learning_rate:\n    for j in n_estimators:\n        rmse_val=[];\n        print(\"learning_rate : \",i,\" n_estimators: \",j)\n        params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", \"max_depth\": 12,\"learning_rate\" : i,\"n_estimators\": j}\n        gbm = lgb.LGBMRegressor(**params, nthread = 4, n_jobs = -1,early_stopping_rounds=100,silent=True)\n\n        gbm.fit(df_train1_agg, label1_agg,\n        eval_set=[(df_train1_agg, label1_agg),(df_train2_agg, label2_agg)],\n        eval_metric='rmse',verbose=False)\n        rmse_val.append(gbm.best_score_['valid_1']['rmse'])\n        #\n        gbm.fit(df_train2_agg, label2_agg,\n        eval_set=[(df_train2_agg, label2_agg),(df_train3_agg, label3_agg)],\n        eval_metric='rmse',verbose=False)\n        rmse_val.append(gbm.best_score_['valid_1']['rmse'])\n        #\n        gbm.fit(df_train3_agg, label3_agg,\n        eval_set=[(df_train3_agg, label3_agg),(df_train4_agg, label4_agg)],\n        eval_metric='rmse',verbose=False)\n        rmse_val.append(gbm.best_score_['valid_1']['rmse'])\n        #\n        gbm.fit(df_train4_agg, label4_agg,\n        eval_set=[(df_train4_agg, label4_agg),(df_train5_agg, label5_agg)],\n        eval_metric='rmse',verbose=False)\n        rmse_val.append(gbm.best_score_['valid_1']['rmse'])\n        #\n        gbm.fit(df_train5_agg, label5_agg,\n        eval_set=[(df_train5_agg, label5_agg),(df_train6_agg, label6_agg)],\n        eval_metric='rmse',verbose=False)\n        rmse_val.append(gbm.best_score_['valid_1']['rmse'])\n        arr=np.array(rmse_val)\n        print(rmse_val)   \n        print(\"mean: \",arr.mean(),\" avg: \",arr.std())\n        mean.append(arr.mean())\n        avg.append(arr.std())\n        axis_x.append(str(i)+\"_\"+str(j))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ce3b20f5256e057cc0310707bfeb174d7803916"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(range(len(mean)), mean)\nplt.plot(range(len(avg)), avg)\nplt.xticks(range(len(avg)), axis_x)\nplt.xticks(rotation=90)\nplt.title('model logloss')  \nplt.ylabel('logloss')  \nplt.xlabel('parameters')  \nplt.legend(['mean', 'avg']) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db93566c9d74d7f6ce6423eb3768504fa43995a0"},"cell_type":"markdown","source":"## 5- Trainning and Cross Validation"},{"metadata":{"trusted":true,"_uuid":"05b74015993c541b269406f2a3d20478b366a5e7"},"cell_type":"code","source":"#params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", \"max_depth\": 12, \"min_child_samples\": 20, \"num_leaves\" : 31, \"learning_rate\" : 0.01}\nparams = {\"objective\" : \"regression\", \"metric\" : \"rmse\", \"max_depth\": 4,\"learning_rate\" : 0.01,\"n_estimators\": 1500,\"min_child_samples\": 500,'subsample': 0.9}\ngbm = lgb.LGBMRegressor(**params, nthread = 4, n_jobs = -1,early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d7f72bf3db6fdccf00a593f027aa49ebc3c8389"},"cell_type":"code","source":"train_rmse={}\nvalid_rmse={}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1e155f827386f4c868ecf75e8d1c09b9913a82e"},"cell_type":"code","source":"#fold1\ngbm.fit(df_train1_agg, label1_agg,\n        eval_set=[(df_train1_agg, label1_agg),(df_train2_agg, label2_agg)],\n        eval_metric='rmse',verbose=False)\n\ntrain_rmse.update({'fold1': gbm.best_score_['training']['rmse']}) \nvalid_rmse.update({'fold1': gbm.best_score_['valid_1']['rmse']}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7749bca77dbc2fba0a63c4b516a8164d1c87a30b"},"cell_type":"code","source":"#fold2\ngbm.fit(df_train2_agg, label2_agg,\n        eval_set=[(df_train2_agg, label2_agg),(df_train3_agg, label3_agg)],\n        eval_metric='rmse',verbose=False)\ntrain_rmse.update({'fold2': gbm.best_score_['training']['rmse']}) \nvalid_rmse.update({'fold2': gbm.best_score_['valid_1']['rmse']}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d9c9429a358f52b96bcd00abf952b48ccb795ea"},"cell_type":"code","source":"#fold3\ngbm.fit(df_train3_agg, label3_agg,\n        eval_set=[(df_train3_agg, label3_agg),(df_train4_agg, label4_agg)],\n        eval_metric='rmse',verbose=False)\ntrain_rmse.update({'fold3': gbm.best_score_['training']['rmse']}) \nvalid_rmse.update({'fold3': gbm.best_score_['valid_1']['rmse']}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7e2c018332adc3c2c90b16dbcba03313f88a9cc"},"cell_type":"code","source":"#fold4\ngbm.fit(df_train4_agg, label4_agg,\n        eval_set=[(df_train4_agg, label4_agg),(df_train5_agg, label5_agg)],\n        eval_metric='rmse',verbose=False)\ntrain_rmse.update({'fold4': gbm.best_score_['training']['rmse']}) \nvalid_rmse.update({'fold4': gbm.best_score_['valid_1']['rmse']}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"be5409d85705c3c331f3639544feacdc8040a0ab"},"cell_type":"code","source":"#fold5\ngbm.fit(df_train5_agg, label5_agg,\n        eval_set=[(df_train5_agg, label5_agg),(df_train6_agg, label6_agg)],\n        eval_metric='rmse',verbose=False)\ntrain_rmse.update({'fold5': gbm.best_score_['training']['rmse']}) \nvalid_rmse.update({'fold5': gbm.best_score_['valid_1']['rmse']}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc1ad75e438a9ad3ff2ef0aaac162f93f9f1af33"},"cell_type":"code","source":"#plot k fold logloss\n\nplt.plot(range(len(train_rmse)), train_rmse.values())\nplt.plot(range(len(valid_rmse)), valid_rmse.values())\nplt.xticks(range(len(train_rmse)), list(train_rmse.keys()))\nplt.xticks(rotation=90)\n\nplt.title('model logloss')  \nplt.ylabel('logloss')  \nplt.xlabel('fold')  \nplt.legend(['train', 'valid']) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec2ab1fe02f6af9c4fdc3f7c22630ef247d29c29"},"cell_type":"code","source":"# plot features importances\nlgb.plot_importance(gbm, max_num_features=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2999efac38f6cf8e94f734177f7fd4d16148d237"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2381141618c9b2c65b7e0f6a62356793d1b0cf2d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bafaa730fa52626b19836f783140438a66cee65"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd9bcb39ea7e0198580e689b49d218b2b569f14b"},"cell_type":"code","source":"['month_unique_user_count','day_unique_user_count','weekday_unique_user_count','weekofyear_unique_user_count',\n    'sum_pageviews_per_network_domain','count_pageviews_per_network_domain','mean_pageviews_per_network_domain',\n    'sum_hits_per_network_domain','count_hits_per_network_domain','mean_hits_per_network_domain',\n    'mean_hits_per_day','sum_hits_per_day',\n    'sum_pageviews_per_region','count_pageviews_per_region','mean_pageviews_per_region',\n    'sum_hits_per_network_domain','count_hits_per_network_domain','mean_hits_per_network_domain',\n    'sum_hits_per_region','count_hits_per_region','mean_hits_per_region',\n    'sum_hits_per_country','count_hits_per_country','mean_hits_per_country',\n    'user_pageviews_sum','user_hits_sum',\n    'user_pageviews_count','user_hits_count',\n    'user_pageviews_sum_to_mean','user_hits_sum_to_mean']\n\n#[sum_hits_per_country month_unique_user_count sum_pageviews_per_network_domain mean_pageviews_per_region\n#sum_hits_per_network_domain count_pageviews_per_region sum_hits_per_day mean_pageviews_per_network_domain\n#user_pageviews_sum user_hits_sum day_unique_user_count sum_hits_per_region]\n   \n#print(\"13..............\")\n#df['user_pageviews_to_region'] = df['user_pageviews_sum'] / df['mean_pageviews_per_region']\n#df['user_hits_to_region'] = df['user_hits_sum'] / df['mean_hits_per_region']\n#df['user_pageviews_sum_to_mean'] = df['user_pageviews_sum'] / df['user_pageviews_sum'].mean()\n#df['user_hits_sum_to_mean'] = df['user_hits_sum'] / df['user_hits_sum'].mean()\n#df['user_pageviews_count'] = df.groupby('fullVisitorId')['totals_pageviews'].transform('count')\n#df['user_hits_count'] = df.groupby('fullVisitorId')['totals_hits'].transform('count')\n#df['count_hits_per_country'] = df.groupby('geoNetwork_country')['totals_hits'].transform('count')\n#df['mean_hits_per_country'] = df.groupby('geoNetwork_country')['totals_hits'].transform('mean')\n#df['count_hits_per_region'] = df.groupby('geoNetwork_region')['totals_hits'].transform('count')\n#df['mean_hits_per_region'] = df.groupby('geoNetwork_region')['totals_hits'].transform('mean')\n#df['count_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('count')\n#df['mean_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('mean')\n#df['mean_hits_per_day'] = df.groupby(['Date_Day'])['totals_hits'].transform('mean')\n#df['sum_pageviews_per_region'] = df.groupby('geoNetwork_region')['totals_pageviews'].transform('sum')\n#df['count_pageviews_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_pageviews'].transform('count')\n#df['sum_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('sum')\n#df['count_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('count')\n#df['mean_hits_per_network_domain'] = df.groupby('geoNetwork_networkDomain')['totals_hits'].transform('mean')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}