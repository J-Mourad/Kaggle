{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c95df3c9471ef20c2a748e85c6580e447e2a836b"
   },
   "source": [
    "# || Overview\n",
    "- Objective: In this competition, Kagglers will develop models that identify and flag insincere toxic and misleading content (questions).\n",
    "-  You must predict whether the corresponding question_text is insincere (1) or not (0). \n",
    "- We have a seriuos disbalance - only ~6% of data are positive. So, No wonder the metric for the competition is f1-score.\n",
    "- This is being run as a Kernels Only Competition, requiring that all submissions be made via a Kernel output. \n",
    "- This competition does not allow external data.\n",
    "- Both your training and prediction should fit in a single Kernel.\n",
    "- CPU Kernel <= 6 hours run-time, GPU Kernel <= 2 hours run-time\n",
    "- Submission file must be named \"submission.csv\"\n",
    "- Following the final submission deadline for the competition, your kernel code will be re-run on a privately-held test set that is not provided to you.\n",
    "- Stage 2 files will only be available in Kernels and not available for download.\n",
    "- In **Stage 2**: ( test.csv from 56k  to ~376k rows )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "045fcbcdefdc10540fd16be5e4efa7922125299b"
   },
   "source": [
    "# || References\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecda4fe145da7737f0f80802a50fc71478068698"
   },
   "source": [
    "# || Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "138b441cda58c972b4d3ef919a921f064b9ee672"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import datetime, time, os, re, random, gc\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "# import torch.utils.data\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"F-score is ill-defined and being set to 0.0 due to no predicted samples.\")\n",
    "np.seterr(divide='ignore')\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "54cddd8c5ce130d483a0bc00eae9bb0f9ee4a330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings  sample_submission.csv  test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18e1090df7dc37c25612f726998e415e6e541e52"
   },
   "source": [
    "# || Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7ab19acb9b7870900298b9cdf3707a7f0736642c"
   },
   "outputs": [],
   "source": [
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5275fae0f4cff76b6f76756c2e67058fae14d8c7"
   },
   "source": [
    "# || Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e31d6e126881ee56a1de3efe02fcf309e900ef00"
   },
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "train = pd.read_csv(os.path.join(path, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(path, \"test.csv\"))\n",
    "sub = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "18466695a4f9329bbc2ea230dbb95355439f3a27"
   },
   "outputs": [],
   "source": [
    "# print('Available Embeddings:', os.listdir(os.path.join(path, \"embeddings/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d3c1c3b57b1abc749a238da66bc56726c23076c7"
   },
   "outputs": [],
   "source": [
    "# train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0244a539c0be65d0fa2badacd0067d6b75b7a623"
   },
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "559837cc330ef98fad36c52db89aabca52f5e3b1"
   },
   "outputs": [],
   "source": [
    "# for s, df in zip([\"Train\", \"Test\"], [train, test]):\n",
    "#     print(\"# Questions in\", s)\n",
    "#     print('\\t Average length: {0:.0f}'. format(np.mean(df['question_text'].apply(lambda x: len(x.split())))))\n",
    "#     print('\\t Average char length: {0:.0f}'. format(np.mean(df['question_text'].apply(lambda x: len(x)))))\n",
    "#     print('\\t Max length: {0:.0f}\\n'. format(np.max(df['question_text'].apply(lambda x: len(x.split())))))\n",
    "# # There are quite long questions in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "aac2da7ceb50c4c481364c2a2985c25401541cf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:12<00:00, 107417.78it/s]\n",
      "100%|██████████| 1306122/1306122 [00:20<00:00, 63914.89it/s]\n",
      "100%|██████████| 375806/375806 [00:03<00:00, 108102.46it/s]\n",
      "100%|██████████| 375806/375806 [00:05<00:00, 64276.43it/s]\n"
     ]
    }
   ],
   "source": [
    "puncts = {',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '~', '•',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√'}\n",
    "mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\", \"haven't\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\", \"i'd\" : \"I would\", \"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"that's\" : \"that is\", \"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\", \"they'll\" : \"they will\", \"they're\" : \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\", \"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\", \"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\", \"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\",\n",
    "\"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n",
    "\n",
    "########  Clean Text  ########\n",
    "# Clean speelings\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "def stemming(x):\n",
    "    x = x.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in x]\n",
    "    return  \" \".join(stemmed_words)\n",
    "\n",
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{2,}', ' ## ', x)\n",
    "    return x\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "    df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: preprocess(x))\n",
    "    # df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "    # df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: stemming(x))\n",
    "    # df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "\n",
    "max_features = 120000\n",
    "# tk = Tokenizer(lower = True, filters = ''.join(puncts), num_words=max_features)\n",
    "tk = Tokenizer(lower = True, num_words=max_features)\n",
    "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
    "tk.fit_on_texts(full_text)\n",
    "\n",
    "word_index = tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "09ff282756360eeaae54f66472c31959c63c3281"
   },
   "outputs": [],
   "source": [
    "# len(word_index) # 200627  # 158007 #-> Contains number: 14980\n",
    "# t = []\n",
    "# for w in word_index.keys(): \n",
    "#     if bool(re.search(r'\\d', w)): t.append(w)\n",
    "# len(t)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6c1e5187a492d011f77c3e42ee98e5f16a44c25d"
   },
   "outputs": [],
   "source": [
    "train_tokenizerd = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
    "test_tokenizerd = tk.texts_to_sequences(test['question_text'].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4f2ce8dfcd6eb121b3544ac1beedaf225c5b1249"
   },
   "outputs": [],
   "source": [
    "# train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist'); plt.yscale('log');\n",
    "# plt.title('Distribution of question text length in characters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "828d99779f9c77abecf1f169ad90ee165e8c245e"
   },
   "outputs": [],
   "source": [
    "# Let's try having sequence length equal to 70 for now\n",
    "max_len = 72\n",
    "X_train = pad_sequences(train_tokenizerd, max_len)\n",
    "X_test = pad_sequences(test_tokenizerd, max_len)\n",
    "\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ff967574539302506cf95febc0c1c441c32e96b6"
   },
   "outputs": [],
   "source": [
    "## Preparing Data for pytorch:\n",
    "# One of main differences from Keras is preparing data. \n",
    "# Pytorch requires special dataloaders. I'll write a class for it\n",
    "\n",
    "y_train = train['target'].values\n",
    "splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=10).split(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11c93b578626254a9dfa361733201d4fea936428"
   },
   "source": [
    "# || Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c58cacb781b92ea3b4f4ac9b05c40ccd26c9fd55"
   },
   "outputs": [],
   "source": [
    "## GloVe: Global Vectors for Word Representation\n",
    "# Form : \"Word 300_float32 \"\n",
    "# *arr for variable number of arrays\n",
    "\n",
    "# load_glove_fast\n",
    "def load_glove(word_index, max_words=200000, embed_size=300):\n",
    "    s = \"\"\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    emb_mean, emb_std = -0.005838499, 0.48782197\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
    "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word not in word_index:\n",
    "                continue\n",
    "            i = word_index[word]\n",
    "            if i >= max_words:\n",
    "                continue\n",
    "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
    "            if len(embedding_vector) == 300:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix, \n",
    "\n",
    "def load_para(word_index, max_words=200000, embed_size=300):\n",
    "    EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "\n",
    "    emb_mean, emb_std = -0.0053247833, 0.49346462\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
    "    with open(EMBEDDING_FILE, 'r', encoding=\"latin-1\") as f:\n",
    "        for line in f:\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word not in word_index:\n",
    "                continue\n",
    "            i = word_index[word]\n",
    "            if i >= max_words:\n",
    "                continue\n",
    "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:embed_size]\n",
    "            if len(embedding_vector) == embed_size:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "194b86508a14be30b1eaae1a58e6599edde3b0f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 5.96 s, total: 39.5 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_matrix_1 = load_glove(word_index, max_words=max_features)\n",
    "embedding_matrix_2 = load_para(word_index, max_words=max_features)\n",
    "#embedding_matrix_3 = load_fasttext(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "74c315d653c7c55fdae36e83c8f71f754b5bad0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.save(\"word_index.npy\",word_index)\n",
    "# word_index = np.load(\"word_index.npy\").item()\n",
    "np.shape(embedding_matrix_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c37c1814f56b89fbe64d6b492dd50dd06f274089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simple average: http://aclweb.org/anthology/N18-2031 \n",
    "embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_2], axis = 0)[0]\n",
    "\n",
    "del embedding_matrix_1, embedding_matrix_2\n",
    "gc.collect()\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e3c121fd2f59728c2a396a909f4b887a456a1f1"
   },
   "source": [
    "# || Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "33b239a734b55b63679c1dd3e42f0c8861b40464"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias: self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias: eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None: a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        \n",
    "        return torch.sum(weighted_input, 1)\n",
    "    \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        hidden_size = 128\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.lstm_attention = Attention(hidden_size*2, max_len)\n",
    "        self.gru_attention = Attention(hidden_size*2, max_len)\n",
    "        \n",
    "        self.linear = nn.Linear(1536, 256)\n",
    "        self.linear1 = nn.Linear(256, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
    "        \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_gru, _ = self.gru(h_lstm)\n",
    "        \n",
    "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
    "        h_gru_atten = self.gru_attention(h_gru)\n",
    "        \n",
    "        avg_pool_g = torch.mean(h_gru, 1)\n",
    "        max_pool_g, _ = torch.max(h_gru, 1)\n",
    "        \n",
    "        avg_pool_l = torch.mean(h_lstm, 1)\n",
    "        max_pool_l, _ = torch.max(h_lstm, 1)\n",
    "        \n",
    "        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool_g, max_pool_g, avg_pool_l, max_pool_l), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        conc = self.relu(self.linear1(conc))\n",
    "        out = self.out(conc)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "82f143338ec232d4f05cfcb6d81063eb20ab40da"
   },
   "outputs": [],
   "source": [
    "m = NeuralNet()\n",
    "x_test_cuda = torch.tensor(X_test, dtype=torch.long).cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "batch_size = 512\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "seed=1029\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89794c922e422b9f2765fa00451bd02e8ada3b4f"
   },
   "source": [
    "# || Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "becb459c6cc660efaf58869939db50842f8dc617"
   },
   "outputs": [],
   "source": [
    "def train_model_full(X_train=X_train, y_train=y_train, splits=splits, n_epochs=5, batch_size=batch_size, validate=False):\n",
    "    train_preds = np.zeros(len(X_train))\n",
    "    test_preds = np.zeros((len(test), len(splits)))\n",
    "    scores = []\n",
    "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f'Fold {i + 1}. {time.ctime()}')\n",
    "        x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.long).cuda()\n",
    "        y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
    "        x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.long).cuda()\n",
    "        y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
    "        \n",
    "        seed_everything(seed + i)\n",
    "        model = NeuralNet()\n",
    "        model.cuda()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        # scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "        \n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean').cuda()\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "        valid_dataset = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_f1 = 0\n",
    "        best_model_name = ''\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print()\n",
    "            print(f'Epoch {epoch}. {time.ctime()}')\n",
    "            model.train()\n",
    "            avg_loss = 0.\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                # print(x_batch.shape)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            valid_preds = np.zeros((x_val_fold.size(0)))\n",
    "\n",
    "            if validate:\n",
    "                avg_val_loss = 0.\n",
    "                for j, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "                    y_pred = model(x_batch).detach()\n",
    "\n",
    "                    avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                    valid_preds[j * batch_size:(j+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "                best_th, score = scoring(y_val_fold.cpu().numpy(), valid_preds, verbose=True)\n",
    "\n",
    "#                 if score > best_f1:\n",
    "#                     best_f1 = score\n",
    "#                     torch.save(model.state_dict(), f'model_{epoch}.pt')\n",
    "#                     best_model_name = f'model_{epoch}.pt'\n",
    "#                 else:\n",
    "#                     print('Stopping training on this fold')\n",
    "#                     break\n",
    "        \n",
    "#         if score < best_f1:\n",
    "#             checkpoint = torch.load(best_model_name)\n",
    "#             model.load_state_dict(checkpoint)\n",
    "#             model.eval()\n",
    "\n",
    "        valid_preds = np.zeros((x_val_fold.size(0)))\n",
    "\n",
    "        avg_val_loss = 0.\n",
    "        for j, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            y_pred = model(x_batch).detach()\n",
    "\n",
    "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "            valid_preds[j * batch_size:(j+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "        best_th, score = scoring(y_val_fold.cpu().numpy(), valid_preds, verbose=True)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        test_preds_fold = np.zeros((len(test_loader.dataset)))\n",
    "\n",
    "        for j, (x_batch,) in enumerate(test_loader):\n",
    "            y_pred = model(x_batch).detach()\n",
    "\n",
    "            test_preds_fold[j * batch_size:(j+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "        train_preds[valid_idx] = valid_preds\n",
    "        test_preds[:, i] = test_preds_fold\n",
    "    print(f'Finished training at {time.ctime()}')\n",
    "    print(f'Mean validation f1-score: {np.mean(scores)}. Std: {np.std(scores)}')\n",
    "    \n",
    "    return train_preds, test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f31dc14b238402631a397a4d053c326e9e5313e7"
   },
   "source": [
    "# || Searching for optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "616683f3289a743d245b4ac5dcdaa047db933a7c"
   },
   "outputs": [],
   "source": [
    "def scoring(y_true, y_proba, verbose=True):\n",
    "    # https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/76391\n",
    "    \n",
    "    def threshold_search1(y_true, y_proba):\n",
    "        precision , recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "        thresholds = np.append(thresholds, 1.001) \n",
    "        F = 2 / (1/precision + 1/recall)\n",
    "        best_score = np.max(F)\n",
    "        best_th = thresholds[np.argmax(F)]\n",
    "        return best_th \n",
    "\n",
    "    # rkf = RepeatedStratifiedKFold(n_splits=4, n_repeats=10)\n",
    "    rkf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "    scores = []\n",
    "    ths = []\n",
    "    for train_index, test_index in rkf.split(y_true, y_true):\n",
    "        y_prob_train, y_prob_test = y_proba[train_index], y_proba[test_index]\n",
    "        y_true_train, y_true_test = y_true[train_index], y_true[test_index]\n",
    "\n",
    "        # determine best threshold on 'train' part \n",
    "        best_threshold = threshold_search1(y_true_train, y_prob_train)\n",
    "\n",
    "        # use this threshold on 'test' part for score \n",
    "        sc = f1_score(y_true_test, (y_prob_test >= best_threshold).astype(int))\n",
    "        scores.append(sc)\n",
    "        ths.append(best_threshold)\n",
    "\n",
    "    best_th = np.mean(ths)\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    if verbose: print(f'Best threshold: {np.round(best_th, 4)}, Score: {np.round(score,5)}')\n",
    "\n",
    "    return best_th, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffd9f48cdf4da007c060fdac51f6a2c71aa25040"
   },
   "source": [
    "# || Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "f9b0a9a028795eab4fe443bca75db12a26264703",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1. Mon Feb 11 12:29:59 2019\n",
      "\n",
      "Epoch 0. Mon Feb 11 12:30:01 2019\n",
      "Best threshold: 0.325, Score: 0.66123\n",
      "\n",
      "Epoch 1. Mon Feb 11 12:35:16 2019\n",
      "Best threshold: 0.3348, Score: 0.68037\n",
      "\n",
      "Epoch 2. Mon Feb 11 12:40:31 2019\n",
      "Best threshold: 0.2672, Score: 0.68415\n",
      "\n",
      "Epoch 3. Mon Feb 11 12:45:45 2019\n",
      "Best threshold: 0.2751, Score: 0.67929\n",
      "\n",
      "Epoch 4. Mon Feb 11 12:50:59 2019\n",
      "Best threshold: 0.4261, Score: 0.67654\n",
      "Best threshold: 0.4261, Score: 0.67654\n",
      "Fold 2. Mon Feb 11 12:57:16 2019\n",
      "\n",
      "Epoch 0. Mon Feb 11 12:57:18 2019\n",
      "Best threshold: 0.2546, Score: 0.66098\n",
      "\n",
      "Epoch 1. Mon Feb 11 13:02:30 2019\n",
      "Best threshold: 0.3037, Score: 0.67513\n",
      "\n",
      "Epoch 2. Mon Feb 11 13:07:43 2019\n",
      "Best threshold: 0.3081, Score: 0.68489\n",
      "\n",
      "Epoch 3. Mon Feb 11 13:12:54 2019\n",
      "Best threshold: 0.3229, Score: 0.68437\n",
      "\n",
      "Epoch 4. Mon Feb 11 13:18:06 2019\n",
      "Best threshold: 0.3966, Score: 0.68083\n",
      "Best threshold: 0.3966, Score: 0.68083\n",
      "Fold 3. Mon Feb 11 13:24:22 2019\n",
      "\n",
      "Epoch 0. Mon Feb 11 13:24:24 2019\n",
      "Best threshold: 0.2383, Score: 0.6607\n",
      "\n",
      "Epoch 1. Mon Feb 11 13:29:37 2019\n",
      "Best threshold: 0.3101, Score: 0.67254\n",
      "\n",
      "Epoch 2. Mon Feb 11 13:34:49 2019\n",
      "Best threshold: 0.3385, Score: 0.67962\n",
      "\n",
      "Epoch 3. Mon Feb 11 13:40:02 2019\n",
      "Best threshold: 0.3003, Score: 0.67809\n",
      "\n",
      "Epoch 4. Mon Feb 11 13:45:14 2019\n",
      "Best threshold: 0.2408, Score: 0.67441\n",
      "Best threshold: 0.2408, Score: 0.67441\n",
      "Fold 4. Mon Feb 11 13:51:31 2019\n",
      "\n",
      "Epoch 0. Mon Feb 11 13:51:32 2019\n",
      "Best threshold: 0.237, Score: 0.66113\n",
      "\n",
      "Epoch 1. Mon Feb 11 13:56:45 2019\n",
      "Best threshold: 0.3143, Score: 0.67671\n",
      "\n",
      "Epoch 2. Mon Feb 11 14:01:57 2019\n",
      "Best threshold: 0.3454, Score: 0.68101\n",
      "\n",
      "Epoch 3. Mon Feb 11 14:07:10 2019\n",
      "Best threshold: 0.3216, Score: 0.67918\n",
      "\n",
      "Epoch 4. Mon Feb 11 14:12:21 2019\n",
      "Best threshold: 0.257, Score: 0.67421\n",
      "Best threshold: 0.257, Score: 0.67421\n",
      "Finished training at Mon Feb 11 14:18:38 2019\n",
      "Mean validation f1-score: 0.6764979648133118. Std: 0.002660135143011669\n"
     ]
    }
   ],
   "source": [
    "train_preds, test_preds = train_model_full(X_train=X_train, y_train=y_train, splits=splits, n_epochs=5, batch_size=batch_size, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "aec5d2d0ad78b436996521274ca78d422c7e5f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.333, Score: 0.67296\n"
     ]
    }
   ],
   "source": [
    "best_th, score = scoring(y_train, train_preds)\n",
    "sub['prediction'] = (test_preds.mean(1) > best_th).astype(int)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a67016bb01fa722134253ed1b8e32093b6332cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel run time = 1.8620194762945175 hours\n"
     ]
    }
   ],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
